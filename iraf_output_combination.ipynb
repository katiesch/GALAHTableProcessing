{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program takes the information from the Observations, Objects, and iraf_dr5.1 tables and combines it into a single table, with a row per object. \n",
    "\n",
    "It also pulls information for each target from APASS, 2MASS, and UCAC4 based on RA/Dec matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the table of observations produced by Janez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_data=pd.read_csv(\"/Users/kschles/Documents/GALAH/iraf_v5.1/observations.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate science observations. Here I remove calibration images (biases/flats/arcs). I also extract all observations with CCD1 because I don't need to know all the information from each CCD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_data['ccd']=((obs_data['runccd_id'].astype(str)).str[10:11]).astype(int)\n",
    "obs1_data=obs_data.loc[np.where((obs_data['ccd']==1) & ((obs_data['ndfclass_updated']=='MFOBJECT') | (obs_data['ndfclass_updated']=='MFFLX')))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the observations by cob_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=obs1_data.groupby(['cob_id'], as_index=False)\n",
    "cobid_obsdata=temp.agg({'runccd_id': 'first', 'ccd' : 'first', 'plate' : 'first', 'cfg_file': 'first', 'cenra': 'first', 'cendec': 'first', 'obsid': 'first', 'exposed': np.sum, 'std_name': 'first', 'qflag': 'first', 'oclass': 'first','ndfclass_updated': 'first'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the IRAF output table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iraf_data=pd.read_csv(\"/Users/kschles/Documents/GALAH/iraf_v5.1/iraf_dr51_03072016.csv\")\n",
    "iraf_data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "iraf_data['cob_id']=((iraf_data['name'].astype(str)).str[0:10]).astype(int)\n",
    "iraf_data['cobpivot']=((iraf_data['name'].astype(str)).str[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than being by object, the IRAF output table is organised by object AND ccd. So each observed object has a row for each CCD. To get the GUESS info for each CCD, I have to break it down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CCD1 Data\n",
    "ccd1_data=iraf_data.loc[np.where(iraf_data['ccd']==1)[0], ['cobpivot', 'v', 'snr', 'snr2', 'snr_guess']]\n",
    "ccd1_data.rename(columns={'v': 'v_ccd1', 'snr' : 'snr_1', 'snr2' : 'snr2_1', 'snr_guess' : 'snr_guess_1'}, inplace=True)\n",
    "ccd2_data=iraf_data.loc[np.where(iraf_data['ccd']==2)[0], ['cobpivot', 'v',  'snr', 'snr2', 'snr_guess']]\n",
    "ccd2_data.rename(columns={'v': 'v_ccd2', 'snr' : 'snr_2', 'snr2' : 'snr2_2', 'snr_guess' : 'snr_guess_2'}, inplace=True)\n",
    "ccd3_data=iraf_data.loc[np.where(iraf_data['ccd']==3)[0], ['cobpivot', 'v',  'snr', 'snr2', 'snr_guess']]\n",
    "ccd3_data.rename(columns={'v': 'v_ccd3', 'snr' : 'snr_3', 'snr2' : 'snr2_3', 'snr_guess' : 'snr_guess_3'}, inplace=True)\n",
    "ccd4_data=iraf_data.loc[np.where(iraf_data['ccd']==4)[0], ['cobpivot',  'v', 'snr', 'snr2', 'snr_guess']]\n",
    "ccd4_data.rename(columns={'v': 'v_ccd4', 'snr' : 'snr_4', 'snr2' : 'snr2_4', 'snr_guess' : 'snr_guess_4'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim down to one entry per object, rather than one entry per object and CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iraf_agg=iraf_data[['name', 'cobpivot','cob_id', 'pivot', 'dirname', 'mag', 'radeg', 'dedeg', 'glon', 'glat', 'ebv', 'teff', 'logg', 'feh', 'combine_method', 'galah_id', 'v_comb', 'wavelength_flag']].groupby('cobpivot', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now combine the information from the other CCDs into the main table. This will give you one row \n",
    "## per combined spectra with the information from each CCD in an individual column. \n",
    "temp1=pd.merge(iraf_agg, ccd1_data, how='left', on='cobpivot')\n",
    "temp2=pd.merge(temp1, ccd2_data, how='left', on='cobpivot')\n",
    "temp3=pd.merge(temp2, ccd3_data, how='left', on='cobpivot')\n",
    "iraf_output=pd.merge(temp3, ccd4_data, how='left', on='cobpivot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The GUESS values are often set to 999. or 9999. rather than null. So I need to adjust this. \n",
    "## Note also that v_ccd4 is invalid; it is merely a copy of v_comb. \n",
    "iraf_output.loc[np.where(iraf_output['v_ccd1'].astype(float)==999.)[0],'v_ccd1']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['v_ccd2'].astype(float)==999.)[0],'v_ccd2']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['v_ccd3'].astype(float)==999.)[0],'v_ccd3']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['v_ccd4'].astype(float)==999.)[0],'v_ccd4']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['teff'].astype(float)==9999.)[0],'teff']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['logg'].astype(float)==9999.)[0],'logg']=np.nan\n",
    "iraf_output.loc[np.where(iraf_output['feh'].astype(float)==9999.)[0],'feh']=np.nan\n",
    "\n",
    "## Recalculate the mean and std radial velocity now that the values are not 999. Janez's v_comb\n",
    "## combines v_ccd1, v_ccd2, and v_ccd3 as a weighted average (where the weights come from S/N). \n",
    "## However, this was done with 999. values rather than NaN which makes many of the values invalid. \n",
    "## Here I recalculate the mean RV and standard deviation without any weighting or 999. values. \n",
    "iraf_output['vmean']=iraf_output.loc[:, ['v_ccd1', 'v_ccd2', 'v_ccd3']].astype(float).mean(axis=1)\n",
    "iraf_output['vstd']=iraf_output.loc[:, ['v_ccd1', 'v_ccd2', 'v_ccd3']].astype(float).std(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we want to match the IRAF output table with the observations table based on cob_id. Each object will now have information about the field observation in its row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combo1=pd.merge(iraf_output,cobid_obsdata[['cenra', 'cendec', 'qflag', 'std_name', 'cfg_file', 'obsid', 'ndfclass_updated', 'cob_id', 'runccd_id']], how=\"left\", on=\"cob_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now want to match up the information in combo1 (observations+IRAF output) with the information from the objects table because I want info like objects.name and objects.comment. The objects table is huge, so, using Jeffrey's bash script, I've split it up by night. We match up the big_combo table with the objects table on a night by night basis using cob_id and pivot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This groups the objects in combo1 table by date and creates a list of each date used. \n",
    "date_grouping=combo1.groupby('dirname')\n",
    "date_list=combo1[['dirname']].groupby('dirname', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131123\n",
      "131216\n",
      "131218\n",
      "131222\n",
      "140117\n",
      "140207\n",
      "140208\n",
      "140209\n",
      "140210\n",
      "140212\n",
      "140303\n",
      "140304\n",
      "140305\n",
      "140307\n",
      "140308\n",
      "140309\n",
      "140310\n",
      "140311\n",
      "140312\n",
      "140313\n",
      "140314\n",
      "140315\n",
      "140316\n",
      "140409\n",
      "140410\n",
      "140412\n",
      "140413\n",
      "140414\n",
      "140415\n",
      "140607\n",
      "140608\n",
      "140609\n",
      "140610\n",
      "140611\n",
      "140707\n",
      "140708\n",
      "140709\n",
      "140710\n",
      "140711\n",
      "140712\n",
      "140713\n",
      "140805\n",
      "140806\n",
      "140807\n",
      "140813\n",
      "140814\n",
      "141101\n",
      "141102\n",
      "141103\n",
      "141104\n",
      "141202\n",
      "141231\n",
      "150101\n",
      "150102\n",
      "150103\n",
      "150105\n",
      "150106\n",
      "150107\n",
      "150108\n",
      "150109\n",
      "150112\n",
      "150204\n",
      "150205\n",
      "150206\n",
      "150207\n",
      "150208\n",
      "150209\n",
      "150210\n",
      "150211\n",
      "150330\n",
      "150401\n",
      "150402\n",
      "150403\n",
      "150404\n",
      "150405\n",
      "150406\n",
      "150407\n",
      "150408\n",
      "150409\n",
      "150410\n",
      "150411\n",
      "150412\n",
      "150413\n",
      "150426\n",
      "150427\n",
      "150428\n",
      "150429\n",
      "150430\n",
      "150504\n",
      "150531\n",
      "150601\n",
      "150602\n",
      "150603\n",
      "150604\n",
      "150605\n",
      "150607\n",
      "150703\n",
      "150704\n",
      "150705\n",
      "150706\n",
      "150718\n",
      "150719\n",
      "150824\n",
      "150826\n",
      "150827\n",
      "150828\n",
      "150829\n",
      "150830\n",
      "150831\n",
      "150901\n",
      "150902\n",
      "150903\n",
      "151008\n",
      "151009\n",
      "151109\n",
      "151110\n",
      "151111\n",
      "151219\n",
      "151220\n",
      "151224\n",
      "151225\n",
      "151226\n",
      "151227\n",
      "151228\n",
      "151230\n",
      "151231\n",
      "160106\n",
      "160107\n",
      "160108\n",
      "160109\n",
      "160110\n",
      "160111\n",
      "160112\n",
      "160123\n",
      "160124\n",
      "160125\n",
      "160126\n",
      "160129\n",
      "160130\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(date_list)):\n",
    "    ## Use the aggregate table to pull out each individual date\n",
    "    date_name=np.array(date_list.loc[i])[0].astype(int)\n",
    "    print date_name\n",
    "    ## Pulls out all of the target observations for that night, organised by COB_ID and Pivot\n",
    "    extract=date_grouping.get_group(date_name)\n",
    "    \n",
    "    ## Read in the objects table for that night\n",
    "    filename='/Users/kschles/Documents/GALAH/iraf_v5.1/objects_by_date/'+date_name.astype(str)+'.txt'\n",
    "    temp_objects=pd.read_csv(filename, names=['runccd_id','run_id','pivot','fibre','type','ra','dec','x','y','xerr','yerr','theta','object_name','comment','mag','pmra','pmdec','pid','retractor','wlen','galah_id','out_name','airmass','barycentric','heliocentric'],index_col=False, low_memory=False)\n",
    "    \n",
    "    y=pd.merge(extract, temp_objects[['runccd_id', 'pivot', 'object_name', 'comment', 'mag', 'galah_id']], how=\"left\", on=['runccd_id', 'pivot'])\n",
    "    \n",
    "    ## the result dataframe has the combination of big_combo with the objects table and we append the combo from each night. \n",
    "    if (i==0) : \n",
    "        result=y\n",
    "    else :\n",
    "        result=result.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result table has all objects, even those observed as MFFLX stars. Thus, it needs to be cleaned up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clean up the table columns.\n",
    "result2=result.loc[np.where(result['ndfclass_updated'].str.match('MFOBJECT', as_indexer=True)==True)[0],\\\n",
    "       ['cobpivot', 'name', 'cob_id', 'pivot', 'dirname', 'mag_x', 'radeg',\\\n",
    "       'dedeg', 'glon', 'glat', 'ebv', 'teff', 'logg', 'feh',\\\n",
    "       'combine_method', 'galah_id_x', 'vmean', 'vstd', 'v_ccd1', 'snr_1',\\\n",
    "       'snr2_1', 'snr_guess_1', 'v_ccd2', 'snr_2', 'snr2_2', 'snr_guess_2',\\\n",
    "       'v_ccd3', 'snr_3', 'snr2_3', 'snr_guess_3', 'v_ccd4', 'snr_4',\\\n",
    "       'snr2_4', 'snr_guess_4', 'cenra', 'cendec', 'qflag', 'std_name',\\\n",
    "       'cfg_file', 'obsid', 'ndfclass_updated', 'runccd_id', 'object_name',\\\n",
    "       'comment', 'wavelength_flag']]\n",
    "result2.reset_index(drop=True, inplace=True)\n",
    "result2.rename(columns={'mag_x' : 'mag', 'galah_id_x' : 'galah_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use STILTS to match up the table with 2MASS, APASS, and UCAC4. Searching for a match for each target in the result2 table within 1 arcsecond. \n",
    "\n",
    "2MASS catalog is II/246/out \n",
    "\n",
    "UCAC4 catalog is 'I/322A/out' \n",
    "\n",
    "PPMXL is 'I/317'\n",
    "\n",
    "SPM is 'I/320'\n",
    "\n",
    "The USNO-B catalog is 'I/284/out'\n",
    "\n",
    "If the OS command returns a 0, all is well with the matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First output the file to a temporary csv. \n",
    "result2[['cob_id', 'pivot', 'radeg', 'dedeg']].to_csv('result_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Then query 2MASS with these targets. stilts.jar must be in your working directory. \n",
    "os.system('java -jar stilts.jar cdsskymatch cdstable=II/246/out find=each in=result_temp.csv ifmt=csv ra=radeg dec=dedeg radius=1 out=result_temp_2mass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Query UCAC4 with STILTS and target list \n",
    "os.system('java -jar stilts.jar cdsskymatch cdstable=I/322A/out find=each in=result_temp.csv ifmt=csv ra=radeg dec=dedeg radius=1 out=result_temp_ucac4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query APASS with STILTS and target list \n",
    "os.system('java -jar stilts.jar cdsskymatch cdstable=II/336/apass9 find=each in=result_temp.csv ifmt=csv ra=radeg dec=dedeg radius=1 out=result_temp_apass.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the relevant data tables, match them with the results2 table based on cob_id and pivot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read in the data you just pulled. \n",
    "twomass_data=pd.read_csv('result_temp_2mass.csv')\n",
    "ucac4_data=pd.read_csv('result_temp_ucac4.csv')\n",
    "#usnob_data=pd.read_csv('result_temp_usnob.csv')\n",
    "apass_data=pd.read_csv('result_temp_apass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1=pd.merge(result2, twomass_data[['cob_id', 'pivot', '2MASS', 'Jmag', 'e_Jmag', \\\n",
    "                                     'Hmag', 'e_Hmag', 'Kmag', 'e_Kmag', 'Qfl', 'Rfl', 'X']], how='left', on=['cob_id', 'pivot'])\n",
    "temp2=pd.merge(temp1, ucac4_data[['cob_id', 'pivot', 'UCAC4', 'pmRA', 'e_pmRA', 'pmDE', 'e_pmDE']], how='left', on=['cob_id', 'pivot'])\n",
    "combined_table=pd.merge(temp2, apass_data[['cob_id', 'pivot', 'Vmag', 'e_Vmag', 'Bmag', 'e_Bmag', \n",
    "                                 'gpmag', 'e_gpmag', 'rpmag', 'e_rpmag', 'ipmag', 'e_ipmag']], how='left', on=['cob_id', 'pivot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Adjust column names\n",
    "combined_table.rename(columns={'2MASS' : '2MASS_ID', 'UCAC4' : 'UCAC4_ID', 'teff' : 'TEFF_GUESS', \\\n",
    "                              'logg' : 'LOGG_GUESS', 'feh' : 'FEH_GUESS', 'qflag' : 'RED_QFLAG', \\\n",
    "                              'galah_id' : 'GALAH_ID'}, inplace=True)\n",
    "## Shift all to upper case\n",
    "combined_table.columns = [x.upper() for x in combined_table.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COBPIVOT', 'NAME', 'COB_ID', 'PIVOT', 'DIRNAME', 'MAG', 'RADEG',\n",
       "       'DEDEG', 'GLON', 'GLAT', 'EBV', 'TEFF_GUESS', 'LOGG_GUESS',\n",
       "       'FEH_GUESS', 'COMBINE_METHOD', 'GALAH_ID', 'VMEAN', 'VSTD',\n",
       "       'V_CCD1', 'SNR_1', 'SNR2_1', 'SNR_GUESS_1', 'V_CCD2', 'SNR_2',\n",
       "       'SNR2_2', 'SNR_GUESS_2', 'V_CCD3', 'SNR_3', 'SNR2_3', 'SNR_GUESS_3',\n",
       "       'V_CCD4', 'SNR_4', 'SNR2_4', 'SNR_GUESS_4', 'CENRA', 'CENDEC',\n",
       "       'RED_QFLAG', 'STD_NAME', 'CFG_FILE', 'OBSID', 'NDFCLASS_UPDATED',\n",
       "       'RUNCCD_ID', 'OBJECT_NAME', 'COMMENT', '2MASS_ID', 'JMAG', 'E_JMAG',\n",
       "       'HMAG', 'E_HMAG', 'KMAG', 'E_KMAG', 'QFL', 'RFL', 'X', 'UCAC4_ID',\n",
       "       'PMRA', 'E_PMRA', 'PMDE', 'E_PMDE', 'VMAG', 'E_VMAG', 'BMAG',\n",
       "       'E_BMAG', 'GPMAG', 'E_GPMAG', 'RPMAG', 'E_RPMAG', 'IPMAG', 'E_IPMAG'], dtype=object)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I output the resulting combined table as a CSV to use for other programs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Output to CSV\n",
    "combined_table[['COB_ID', 'PIVOT', 'DIRNAME', 'MAG', 'RADEG', \\\n",
    "       'DEDEG', 'GLON', 'GLAT', 'EBV', 'TEFF_GUESS', 'LOGG_GUESS', \\\n",
    "       'FEH_GUESS', 'COMBINE_METHOD', 'GALAH_ID', 'V_COMB', 'V_CCD1', \\\n",
    "       'SNR_1', 'SNR2_1', 'SNR_GUESS_1', 'V_CCD2', 'SNR_2', 'SNR2_2', \\\n",
    "       'SNR_GUESS_2', 'V_CCD3', 'SNR_3', 'SNR2_3', 'SNR_GUESS_3', 'V_CCD4', \\\n",
    "       'SNR_4', 'SNR2_4', 'SNR_GUESS_4', 'CENRA', 'CENDEC', 'RED_QFLAG', \\\n",
    "       'STD_NAME', 'CFG_FILE', 'OBSID', 'NDFCLASS_UPDATED', 'RUNCCD_ID', \\\n",
    "       'OBJECT_NAME', 'COMMENT', '2MASS_ID', 'JMAG', 'E_JMAG', 'HMAG', \\\n",
    "       'E_HMAG', 'KMAG', 'E_KMAG', 'QFL', 'RFL', 'X','VMAG', 'E_VMAG', \\\n",
    "       'BMAG', 'E_BMAG', 'GPMAG', 'E_GPMAG', 'RPMAG', 'E_RPMAG', \\\n",
    "       'IPMAG', 'E_IPMAG', 'UCAC4_ID', 'PMRA', 'E_PMRA', 'PMDE', 'E_PMDE'\\\n",
    "        ]].to_csv('combined_table_04172016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_table.loc[np.where(combined_table['GALAH_ID'].isnull()==True)[0], 'GALAH_ID']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Output to FITS file \n",
    "\n",
    "## Target Information\n",
    "col01=fits.Column(name='COB_ID', format='I10', array=combined_table['COB_ID'])\n",
    "col02=fits.Column(name='PIVOT', format='I3', array=combined_table['PIVOT'])\n",
    "col03=fits.Column(name='DIRNAME',format='I6', array=combined_table['DIRNAME'])\n",
    "col04=fits.Column(name='GALAH_ID',format='K15', array=combined_table['GALAH_ID'])\n",
    "col05=fits.Column(name='COMBINE_METHOD',format='I', array=combined_table['COMBINE_METHOD'])\n",
    "col06=fits.Column(name='RADEG',format='F',unit='Degrees', array=combined_table['RADEG'])\n",
    "col07=fits.Column(name='DEDEG',format='F',unit='Degrees', array=combined_table['DEDEG'])\n",
    "col08=fits.Column(name='GLON',format='F',unit='Degrees', array=combined_table['GLON'])\n",
    "col09=fits.Column(name='GLAT',format='F',unit='Degrees', array=combined_table['GLAT'])\n",
    "col10=fits.Column(name='CFG_FILE',format='A60', array=combined_table['CFG_FILE'])\n",
    "col11=fits.Column(name='CENRA',format='F', unit='Degrees', array=combined_table['CENRA'])\n",
    "col12=fits.Column(name='CENDEC',format='F', unit='Degrees', array=combined_table['CENDEC'])\n",
    "col13=fits.Column(name='OBJECT_NAME',format='A20', array=combined_table['OBJECT_NAME'])\n",
    "col14=fits.Column(name='COMMENT',format='A20', array=combined_table['COMMENT'])\n",
    "col15=fits.Column(name='EBV',format='F',unit='mag', array=combined_table['EBV'])\n",
    "## GUESS Information\n",
    "col16=fits.Column(name='TEFF_GUESS',format='F', unit='K', array=combined_table['TEFF_GUESS'])\n",
    "col17=fits.Column(name='LOGG_GUESS',format='F', unit='dex', array=combined_table['LOGG_GUESS'])\n",
    "col18=fits.Column(name='FEH_GUESS',format='F', unit='dex', array=combined_table['FEH_GUESS'])\n",
    "col19=fits.Column(name='RV_CCD1',format='F', unit='km/s', array=combined_table['V_CCD1'])\n",
    "col20=fits.Column(name='RV_CCD2',format='F', unit='km/s',array=combined_table['V_CCD2'])\n",
    "col21=fits.Column(name='RV_CCD3',format='F', unit='km/s',array=combined_table['V_CCD3'])\n",
    "col22=fits.Column(name='RV_MEAN',format='F', unit='km/s',array=combined_table['VMEAN'])\n",
    "col23=fits.Column(name='RV_STDDEV',format='F', unit='km/s',array=combined_table['VSTD'])\n",
    "col24=fits.Column(name='FLAG_GUESS',format='L', unit='',array=combined_table['WAVELENGTH_FLAG'])\n",
    "## WHAT ABOUT OTHER GUESS FLAGS?\n",
    "## S/N Information\n",
    "col25=fits.Column(name='SNR_ERROR_CCD1',format='E', unit='',array=combined_table['SNR2_1'])\n",
    "col26=fits.Column(name='SNR_ERROR_CCD2',format='E', unit='',array=combined_table['SNR2_2'])\n",
    "col27=fits.Column(name='SNR_ERROR_CCD3',format='E', unit='',array=combined_table['SNR2_3'])\n",
    "col28=fits.Column(name='SNR_ERROR_CCD4',format='E', unit='',array=combined_table['SNR2_4'])\n",
    "col29=fits.Column(name='SNR_GUESS_CCD1',format='E', unit='',array=combined_table['SNR_GUESS_1'])\n",
    "col30=fits.Column(name='SNR_GUESS_CCD2',format='E', unit='',array=combined_table['SNR_GUESS_2'])\n",
    "col31=fits.Column(name='SNR_GUESS_CCD3',format='E', unit='',array=combined_table['SNR_GUESS_3'])\n",
    "col32=fits.Column(name='SNR_GUESS_CCD4',format='E', unit='',array=combined_table['SNR_GUESS_4'])\n",
    "## 2MASS Information \n",
    "col33=fits.Column(name='2MASS_ID',format='A20', unit='',array=combined_table['2MASS_ID'])\n",
    "col34=fits.Column(name='JMAG',format='E', unit='mag',array=combined_table['JMAG'])\n",
    "col35=fits.Column(name='E_JMAG',format='E', unit='mag',array=combined_table['E_JMAG'])\n",
    "col36=fits.Column(name='HMAG',format='E', unit='mag',array=combined_table['HMAG'])\n",
    "col37=fits.Column(name='E_HMAG',format='E', unit='mag',array=combined_table['E_HMAG'])\n",
    "col38=fits.Column(name='KMAG',format='E', unit='mag',array=combined_table['KMAG'])\n",
    "col39=fits.Column(name='E_KMAG',format='E', unit='mag',array=combined_table['E_KMAG'])\n",
    "col40=fits.Column(name='2MASS_QFL',format='A5', unit='',array=combined_table['QFL'])\n",
    "col41=fits.Column(name='2MASS_RFL',format='I3', unit='',array=combined_table['RFL'])\n",
    "col42=fits.Column(name='2MASS_XFL',format='I1', unit='',array=combined_table['X'])\n",
    "## APASS Information \n",
    "col43=fits.Column(name='BMAG',format='E', unit='mag',array=combined_table['BMAG'])\n",
    "col44=fits.Column(name='E_BMAG',format='E', unit='mag',array=combined_table['E_BMAG'])\n",
    "col45=fits.Column(name='VMAG',format='E', unit='mag',array=combined_table['VMAG'])\n",
    "col46=fits.Column(name='E_VMAG',format='E', unit='mag',array=combined_table['E_VMAG'])\n",
    "col47=fits.Column(name='GPMAG',format='E', unit='mag',array=combined_table['GPMAG'])\n",
    "col48=fits.Column(name='E_GPMAG',format='E', unit='mag',array=combined_table['E_GPMAG'])\n",
    "col49=fits.Column(name='RPMAG',format='E', unit='mag',array=combined_table['RPMAG'])\n",
    "col50=fits.Column(name='E_RPMAG',format='E', unit='mag',array=combined_table['E_RPMAG'])\n",
    "col51=fits.Column(name='IPMAG',format='E', unit='mag',array=combined_table['IPMAG'])\n",
    "col52=fits.Column(name='E_IPMAG',format='E', unit='mag',array=combined_table['E_IPMAG'])\n",
    "## UCAC4 Information \n",
    "col53=fits.Column(name='UCAC4_ID',format='A10', unit='',array=combined_table['UCAC4_ID'])\n",
    "col54=fits.Column(name='PMRA',format='E', unit='mas/yr',array=combined_table['PMRA'])\n",
    "col55=fits.Column(name='E_PMRA',format='E', unit='mas/yr',array=combined_table['E_PMRA'])\n",
    "col56=fits.Column(name='PMDE',format='E', unit='mas/yr',array=combined_table['PMDE'])\n",
    "col57=fits.Column(name='E_PMDE',format='E', unit='mas/yr',array=combined_table['E_PMDE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_ipython().system(u'rm iraf_output_combination.fits')\n",
    "cols=fits.ColDefs([col01,col02,col03,col04,col05,col06,col07,col08,col09,col10,\\\n",
    "                   col11,col12,col13,col14,col15,col16,col17,col18,col19,col20,\\\n",
    "                   col21,col22,col23,col24,col25,col26,col27,col28,col29,col30,\\\n",
    "                   col31,col32,col33,col34,col35,col36,col37,col38,col39,col40,\\\n",
    "                   col41,col42,col43,col44,col45,col46,col47,col48,col49,col50,\\\n",
    "                   col51,col52,col53,col54,col55,col56,col57])\n",
    "tbhdu=fits.BinTableHDU.from_columns(cols)\n",
    "tbhdu.writeto('iraf_output_combination.fits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output to csv with comparable information??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN THE FUTURE WE CAN COMBINE WITH ADDITIONAL INFORMATION, LIKE VALUES FROM TOMAZ AND JANE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now match up with Tomaz' distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objects=pd.read_csv(\"/Users/kschles/Documents/GALAH/iraf_v5.0/objects_table_manipulate_byday.csv\")\n",
    "distances=pd.read_csv('/Users/kschles/Documents/GALAH/distances/zwitter/iraf_final_ed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances['ccd1_filename']=((distances['name'].astype(str)).str[0:15]).astype(int)\n",
    "distances['filename']=distances['name'].astype(str)\n",
    "distances['cob_id']=(distances['filename'].str[0:10]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_combo=pd.merge(objects, distances[['cob_id', 'pivot', 'dmod', 'edmod']], how='left', on=['cob_id', 'pivot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
